{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize Images from google images to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# downloadsdir = './downloads'\n",
    "# dirs = [x for x in os.walk(downloadsdir)]\n",
    "# for shroom in dirs[0][1]:\n",
    "#     resizeddir = './resized\\\\\\\\'+shroom\n",
    "#     fullsizedir = './downloads\\\\\\\\'+shroom\n",
    "#     if not os.path.exists(resizeddir):\n",
    "#         os.makedirs(resizeddir)\n",
    "#     pics = [x[2] for x in os.walk(fullsizedir)]\n",
    "#     for idx, p in enumerate(pics[0]):\n",
    "#         if not p.endswith('.gif'):\n",
    "#             picpath = fullsizedir+'\\\\\\\\'+p\n",
    "#             try:\n",
    "#                 img = cv2.imread(picpath,-1)\n",
    "#                 resized = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "#                 cv2.imwrite(resizeddir+'\\\\\\\\'+str(idx)+'.jpg', resized)\n",
    "#             except:\n",
    "#                 print('Could not process ' + p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1090, 224, 224, 3)\n",
      "(1090,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "num_classes = 16\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "# is_edible = []\n",
    "\n",
    "# mushroom_info = pd.read_json('mushroom_classes.json', lines=True)\n",
    "classdirs = [x for x in os.walk('./resized')]\n",
    "for shroomidx, shroom in enumerate(classdirs[0][1]):\n",
    "#     info = mushroom_info.loc[mushroom_info.name_latin == shroom]\n",
    "#     edible = info.edibility.isin((\"edible\", \"edible and good\", \"edible and excellent\"))\n",
    "#     is_edible.append(edible)\n",
    "    imagepaths = [x for x in os.walk('./resized\\\\\\\\'+shroom)]\n",
    "    for path in imagepaths[0][2]:\n",
    "        img = cv2.imread('./resized\\\\\\\\'+shroom+'\\\\\\\\'+path,-1)\n",
    "        if (img.shape == (224, 224, 3)):\n",
    "            X.append(img)\n",
    "            y.append(shroomidx)\n",
    "\n",
    "X = np.stack(X)\n",
    "y = np.stack(y)\n",
    "# is_edible = pd.Series(is_edible)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# print(is_edible.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test data\n",
    "import keras\n",
    "# rescale !!\n",
    "X = X/255.0\n",
    "\n",
    "N = len(X)\n",
    "N_tr = int(0.8*N)\n",
    "\n",
    "# shuffle the data\n",
    "indx = np.arange(N)\n",
    "np.random.shuffle(indx)\n",
    "X = X[indx]\n",
    "y = y[indx]\n",
    "\n",
    "# split\n",
    "X_tr = X[0:N_tr]\n",
    "y_tr = y[0:N_tr]\n",
    "y_tr = keras.utils.to_categorical(y_tr, num_classes)\n",
    "\n",
    "X_te = X[N_tr:]\n",
    "y_te = y[N_tr:]\n",
    "y_te = keras.utils.to_categorical(y_te, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "# def my_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                      activation='relu',\n",
    "#                      input_shape=X[0].shape))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(Dropout(0.4))\n",
    "#     model.add(Dense(len(is_edible), activation='sigmoid'))\n",
    "#     return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = my_model()\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "basemodel = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224,224,3))\n",
    "for layer in basemodel.layers[1:13]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "topmodel = Sequential()\n",
    "topmodel.add(Flatten(input_shape=basemodel.output_shape[1:]))\n",
    "topmodel.add(Dense(num_classes, activation='relu'))\n",
    "topmodel.add(Dropout(0.4))\n",
    "topmodel.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs = basemodel.input, outputs = topmodel(basemodel.output))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"models/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 16)                401696    \n",
      "=================================================================\n",
      "Total params: 15,116,384\n",
      "Trainable params: 9,840,928\n",
      "Non-trainable params: 5,275,456\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 872 samples, validate on 218 samples\n",
      "Epoch 1/200\n",
      "872/872 [==============================] - 21s 24ms/step - loss: 2.8127 - acc: 0.0562 - val_loss: 2.7728 - val_acc: 0.0505\n",
      "Epoch 2/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7745 - acc: 0.0791 - val_loss: 2.7664 - val_acc: 0.0505\n",
      "Epoch 3/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7711 - acc: 0.0837 - val_loss: 2.7733 - val_acc: 0.0505\n",
      "Epoch 4/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7700 - acc: 0.0803 - val_loss: 2.7735 - val_acc: 0.0505\n",
      "Epoch 5/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7699 - acc: 0.0814 - val_loss: 2.7737 - val_acc: 0.0505\n",
      "Epoch 6/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7699 - acc: 0.0814 - val_loss: 2.7740 - val_acc: 0.0505\n",
      "Epoch 7/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7677 - acc: 0.0837 - val_loss: 2.7742 - val_acc: 0.0505\n",
      "Epoch 8/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7684 - acc: 0.0780 - val_loss: 2.7737 - val_acc: 0.0505\n",
      "Epoch 9/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7599 - acc: 0.0940 - val_loss: 2.7017 - val_acc: 0.1193\n",
      "Epoch 10/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.7125 - acc: 0.0986 - val_loss: 2.6240 - val_acc: 0.1147\n",
      "Epoch 11/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.6708 - acc: 0.1342 - val_loss: 2.5833 - val_acc: 0.2294\n",
      "Epoch 12/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.5390 - acc: 0.1766 - val_loss: 2.5013 - val_acc: 0.2202\n",
      "Epoch 13/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.4350 - acc: 0.2007 - val_loss: 2.3668 - val_acc: 0.2844\n",
      "Epoch 14/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.3550 - acc: 0.2282 - val_loss: 2.3032 - val_acc: 0.4037\n",
      "Epoch 15/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.3050 - acc: 0.2615 - val_loss: 2.1976 - val_acc: 0.4083\n",
      "Epoch 16/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.2095 - acc: 0.3039 - val_loss: 2.1206 - val_acc: 0.4358\n",
      "Epoch 17/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.1388 - acc: 0.3394 - val_loss: 2.0537 - val_acc: 0.4312\n",
      "Epoch 18/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.0784 - acc: 0.3360 - val_loss: 2.1021 - val_acc: 0.3945\n",
      "Epoch 19/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 2.0149 - acc: 0.3406 - val_loss: 2.0773 - val_acc: 0.3670\n",
      "Epoch 20/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.9706 - acc: 0.3429 - val_loss: 1.7999 - val_acc: 0.4266\n",
      "Epoch 21/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.9248 - acc: 0.3865 - val_loss: 1.8877 - val_acc: 0.3670\n",
      "Epoch 22/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.8150 - acc: 0.3624 - val_loss: 1.8146 - val_acc: 0.4954\n",
      "Epoch 23/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.7241 - acc: 0.4117 - val_loss: 1.6345 - val_acc: 0.4725\n",
      "Epoch 24/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.6618 - acc: 0.4278 - val_loss: 1.4271 - val_acc: 0.5138\n",
      "Epoch 25/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.5371 - acc: 0.4622 - val_loss: 1.3455 - val_acc: 0.5872\n",
      "Epoch 26/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.4751 - acc: 0.5057 - val_loss: 1.1097 - val_acc: 0.6514\n",
      "Epoch 27/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.4020 - acc: 0.5321 - val_loss: 1.3821 - val_acc: 0.6284\n",
      "Epoch 28/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.3172 - acc: 0.5631 - val_loss: 1.2784 - val_acc: 0.6697\n",
      "Epoch 29/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.2655 - acc: 0.5677 - val_loss: 1.1713 - val_acc: 0.7064\n",
      "Epoch 30/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.1512 - acc: 0.6101 - val_loss: 1.0275 - val_acc: 0.7661\n",
      "Epoch 31/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.1445 - acc: 0.6135 - val_loss: 0.9444 - val_acc: 0.6881\n",
      "Epoch 32/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 1.0022 - acc: 0.6491 - val_loss: 0.9502 - val_acc: 0.7248\n",
      "Epoch 33/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.9302 - acc: 0.6950 - val_loss: 1.0959 - val_acc: 0.7110\n",
      "Epoch 34/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.9057 - acc: 0.6858 - val_loss: 0.8938 - val_acc: 0.7294\n",
      "Epoch 35/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.8450 - acc: 0.7076 - val_loss: 0.7813 - val_acc: 0.7890\n",
      "Epoch 36/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.7661 - acc: 0.7443 - val_loss: 0.8778 - val_acc: 0.7615\n",
      "Epoch 37/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.6778 - acc: 0.7569 - val_loss: 0.7953 - val_acc: 0.7569\n",
      "Epoch 38/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.6558 - acc: 0.7683 - val_loss: 0.7697 - val_acc: 0.7752\n",
      "Epoch 39/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.6585 - acc: 0.7511 - val_loss: 0.7411 - val_acc: 0.8073\n",
      "Epoch 40/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.6151 - acc: 0.7718 - val_loss: 0.6674 - val_acc: 0.7982\n",
      "Epoch 41/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.5856 - acc: 0.7810 - val_loss: 0.9244 - val_acc: 0.7477\n",
      "Epoch 42/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.5164 - acc: 0.8050 - val_loss: 0.7870 - val_acc: 0.7752\n",
      "Epoch 43/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.5972 - acc: 0.7741 - val_loss: 0.8407 - val_acc: 0.7661\n",
      "Epoch 44/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.4976 - acc: 0.8303 - val_loss: 0.8089 - val_acc: 0.7798\n",
      "Epoch 45/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.4775 - acc: 0.8268 - val_loss: 0.7649 - val_acc: 0.7936\n",
      "Epoch 46/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.4588 - acc: 0.8268 - val_loss: 0.9546 - val_acc: 0.7752\n",
      "Epoch 47/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.4572 - acc: 0.8326 - val_loss: 0.8812 - val_acc: 0.7569\n",
      "Epoch 48/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.4136 - acc: 0.8509 - val_loss: 0.7752 - val_acc: 0.8119\n",
      "Epoch 49/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3702 - acc: 0.8567 - val_loss: 0.7810 - val_acc: 0.7936\n",
      "Epoch 50/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3693 - acc: 0.8624 - val_loss: 0.7920 - val_acc: 0.8165\n",
      "Epoch 51/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.4144 - acc: 0.8544 - val_loss: 0.7875 - val_acc: 0.7982\n",
      "Epoch 52/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3087 - acc: 0.8819 - val_loss: 0.7389 - val_acc: 0.8349\n",
      "Epoch 53/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3612 - acc: 0.8601 - val_loss: 0.8188 - val_acc: 0.8165\n",
      "Epoch 54/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3283 - acc: 0.8635 - val_loss: 0.8043 - val_acc: 0.8303\n",
      "Epoch 55/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3548 - acc: 0.8670 - val_loss: 0.8140 - val_acc: 0.8073\n",
      "Epoch 56/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3358 - acc: 0.8773 - val_loss: 0.8603 - val_acc: 0.8028\n",
      "Epoch 57/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3470 - acc: 0.8693 - val_loss: 0.8946 - val_acc: 0.8211\n",
      "Epoch 58/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3214 - acc: 0.8807 - val_loss: 0.9705 - val_acc: 0.8073\n",
      "Epoch 59/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3245 - acc: 0.8819 - val_loss: 0.9405 - val_acc: 0.8165\n",
      "Epoch 60/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3408 - acc: 0.8761 - val_loss: 0.8796 - val_acc: 0.8165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3048 - acc: 0.8922 - val_loss: 0.9590 - val_acc: 0.8073\n",
      "Epoch 62/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2955 - acc: 0.8968 - val_loss: 0.9466 - val_acc: 0.8073\n",
      "Epoch 63/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3183 - acc: 0.8830 - val_loss: 0.9351 - val_acc: 0.7936\n",
      "Epoch 64/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3236 - acc: 0.8773 - val_loss: 0.8554 - val_acc: 0.8349\n",
      "Epoch 65/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3145 - acc: 0.8819 - val_loss: 0.8196 - val_acc: 0.8349\n",
      "Epoch 66/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3361 - acc: 0.8612 - val_loss: 0.8918 - val_acc: 0.8165\n",
      "Epoch 67/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2955 - acc: 0.8888 - val_loss: 0.9356 - val_acc: 0.8165\n",
      "Epoch 68/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2673 - acc: 0.9025 - val_loss: 0.9104 - val_acc: 0.8165\n",
      "Epoch 69/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2680 - acc: 0.9002 - val_loss: 0.8453 - val_acc: 0.8303\n",
      "Epoch 70/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3175 - acc: 0.8727 - val_loss: 0.8638 - val_acc: 0.8211\n",
      "Epoch 71/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2882 - acc: 0.9048 - val_loss: 0.8888 - val_acc: 0.8303\n",
      "Epoch 72/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2925 - acc: 0.8842 - val_loss: 0.9155 - val_acc: 0.8073\n",
      "Epoch 73/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2823 - acc: 0.8945 - val_loss: 0.9246 - val_acc: 0.8303\n",
      "Epoch 74/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2853 - acc: 0.8922 - val_loss: 0.9007 - val_acc: 0.8211\n",
      "Epoch 75/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2901 - acc: 0.9060 - val_loss: 0.8885 - val_acc: 0.8119\n",
      "Epoch 76/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3034 - acc: 0.8945 - val_loss: 0.9190 - val_acc: 0.8119\n",
      "Epoch 77/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2959 - acc: 0.8911 - val_loss: 0.9025 - val_acc: 0.8165\n",
      "Epoch 78/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.3201 - acc: 0.8842 - val_loss: 0.9390 - val_acc: 0.7936\n",
      "Epoch 79/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2670 - acc: 0.9128 - val_loss: 0.8373 - val_acc: 0.8257\n",
      "Epoch 80/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2598 - acc: 0.9014 - val_loss: 0.8641 - val_acc: 0.8349\n",
      "Epoch 81/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2753 - acc: 0.8968 - val_loss: 0.9630 - val_acc: 0.8257\n",
      "Epoch 82/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2666 - acc: 0.9025 - val_loss: 0.8659 - val_acc: 0.8211\n",
      "Epoch 83/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2656 - acc: 0.8888 - val_loss: 0.9615 - val_acc: 0.8073\n",
      "Epoch 84/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2891 - acc: 0.8933 - val_loss: 0.9412 - val_acc: 0.8211\n",
      "Epoch 85/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2759 - acc: 0.8979 - val_loss: 0.9258 - val_acc: 0.8257\n",
      "Epoch 86/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2675 - acc: 0.9048 - val_loss: 0.8993 - val_acc: 0.8349\n",
      "Epoch 87/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2605 - acc: 0.8968 - val_loss: 0.9643 - val_acc: 0.8211\n",
      "Epoch 88/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2519 - acc: 0.9037 - val_loss: 0.9704 - val_acc: 0.7936\n",
      "Epoch 89/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2519 - acc: 0.9094 - val_loss: 1.0494 - val_acc: 0.7982\n",
      "Epoch 90/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2783 - acc: 0.8991 - val_loss: 1.0417 - val_acc: 0.8028\n",
      "Epoch 91/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2295 - acc: 0.9151 - val_loss: 1.0035 - val_acc: 0.8165\n",
      "Epoch 92/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2312 - acc: 0.9186 - val_loss: 0.9626 - val_acc: 0.8119\n",
      "Epoch 93/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2505 - acc: 0.9083 - val_loss: 0.9944 - val_acc: 0.8211\n",
      "Epoch 94/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2777 - acc: 0.8933 - val_loss: 0.9243 - val_acc: 0.8303\n",
      "Epoch 95/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2573 - acc: 0.9002 - val_loss: 0.9248 - val_acc: 0.8165\n",
      "Epoch 96/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2677 - acc: 0.8888 - val_loss: 0.9416 - val_acc: 0.8028\n",
      "Epoch 97/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2464 - acc: 0.9060 - val_loss: 0.9975 - val_acc: 0.8119\n",
      "Epoch 98/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2114 - acc: 0.9220 - val_loss: 1.0168 - val_acc: 0.8073\n",
      "Epoch 99/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2924 - acc: 0.8876 - val_loss: 0.9468 - val_acc: 0.8394\n",
      "Epoch 100/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2628 - acc: 0.8979 - val_loss: 0.9264 - val_acc: 0.8119\n",
      "Epoch 101/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2414 - acc: 0.9106 - val_loss: 0.8779 - val_acc: 0.8394\n",
      "Epoch 102/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2352 - acc: 0.9106 - val_loss: 0.9426 - val_acc: 0.8165\n",
      "Epoch 103/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2542 - acc: 0.9117 - val_loss: 0.9777 - val_acc: 0.8349\n",
      "Epoch 104/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2483 - acc: 0.9002 - val_loss: 0.9354 - val_acc: 0.8211\n",
      "Epoch 105/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2293 - acc: 0.9163 - val_loss: 0.9494 - val_acc: 0.8211\n",
      "Epoch 106/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2439 - acc: 0.9094 - val_loss: 0.9701 - val_acc: 0.8211\n",
      "Epoch 107/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2271 - acc: 0.9083 - val_loss: 0.9650 - val_acc: 0.8165\n",
      "Epoch 108/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2349 - acc: 0.9094 - val_loss: 1.0149 - val_acc: 0.8165\n",
      "Epoch 109/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2767 - acc: 0.9014 - val_loss: 0.9442 - val_acc: 0.8394\n",
      "Epoch 110/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2328 - acc: 0.9083 - val_loss: 0.9471 - val_acc: 0.8073\n",
      "Epoch 111/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2665 - acc: 0.8979 - val_loss: 0.9362 - val_acc: 0.8211\n",
      "Epoch 112/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2377 - acc: 0.9117 - val_loss: 0.8966 - val_acc: 0.8303\n",
      "Epoch 113/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2115 - acc: 0.9278 - val_loss: 0.9623 - val_acc: 0.8349\n",
      "Epoch 114/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2646 - acc: 0.9002 - val_loss: 1.0933 - val_acc: 0.8165\n",
      "Epoch 115/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2360 - acc: 0.9083 - val_loss: 0.9603 - val_acc: 0.8028\n",
      "Epoch 116/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2395 - acc: 0.9071 - val_loss: 0.9735 - val_acc: 0.8303\n",
      "Epoch 117/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2522 - acc: 0.8899 - val_loss: 0.9673 - val_acc: 0.8303\n",
      "Epoch 118/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2397 - acc: 0.9048 - val_loss: 1.0232 - val_acc: 0.8257\n",
      "Epoch 119/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2502 - acc: 0.9117 - val_loss: 1.0021 - val_acc: 0.8165\n",
      "Epoch 120/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2149 - acc: 0.9083 - val_loss: 1.0975 - val_acc: 0.8073\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2482 - acc: 0.9014 - val_loss: 1.1318 - val_acc: 0.8073\n",
      "Epoch 122/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2251 - acc: 0.9037 - val_loss: 0.9855 - val_acc: 0.8211\n",
      "Epoch 123/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2218 - acc: 0.9163 - val_loss: 1.0204 - val_acc: 0.8303\n",
      "Epoch 124/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2528 - acc: 0.9048 - val_loss: 1.0185 - val_acc: 0.8165\n",
      "Epoch 125/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2486 - acc: 0.8991 - val_loss: 0.9606 - val_acc: 0.8119\n",
      "Epoch 126/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2472 - acc: 0.9014 - val_loss: 0.9788 - val_acc: 0.8349\n",
      "Epoch 127/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2439 - acc: 0.8899 - val_loss: 0.9294 - val_acc: 0.8257\n",
      "Epoch 128/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2125 - acc: 0.9186 - val_loss: 1.0382 - val_acc: 0.8119\n",
      "Epoch 129/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2510 - acc: 0.9048 - val_loss: 1.0975 - val_acc: 0.8257\n",
      "Epoch 130/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2024 - acc: 0.9140 - val_loss: 1.0684 - val_acc: 0.8257\n",
      "Epoch 131/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1971 - acc: 0.9209 - val_loss: 1.0910 - val_acc: 0.8165\n",
      "Epoch 132/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2135 - acc: 0.9140 - val_loss: 1.0740 - val_acc: 0.8211\n",
      "Epoch 133/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2511 - acc: 0.9025 - val_loss: 1.0205 - val_acc: 0.8257\n",
      "Epoch 134/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2108 - acc: 0.9220 - val_loss: 1.1108 - val_acc: 0.8165\n",
      "Epoch 135/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2493 - acc: 0.8945 - val_loss: 1.0356 - val_acc: 0.8257\n",
      "Epoch 136/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2257 - acc: 0.9071 - val_loss: 1.0665 - val_acc: 0.8165\n",
      "Epoch 137/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2730 - acc: 0.8968 - val_loss: 0.9965 - val_acc: 0.8165\n",
      "Epoch 138/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2128 - acc: 0.9186 - val_loss: 1.0064 - val_acc: 0.8394\n",
      "Epoch 139/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2348 - acc: 0.9037 - val_loss: 1.0037 - val_acc: 0.8257\n",
      "Epoch 140/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1891 - acc: 0.9289 - val_loss: 1.0814 - val_acc: 0.8165\n",
      "Epoch 141/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2423 - acc: 0.9002 - val_loss: 0.9786 - val_acc: 0.8211\n",
      "Epoch 142/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2538 - acc: 0.9060 - val_loss: 0.9610 - val_acc: 0.8349\n",
      "Epoch 143/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2392 - acc: 0.9083 - val_loss: 1.0274 - val_acc: 0.8257\n",
      "Epoch 144/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2076 - acc: 0.9197 - val_loss: 0.9939 - val_acc: 0.8394\n",
      "Epoch 145/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1926 - acc: 0.9335 - val_loss: 1.0558 - val_acc: 0.8073\n",
      "Epoch 146/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1969 - acc: 0.9300 - val_loss: 1.0148 - val_acc: 0.8257\n",
      "Epoch 147/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2634 - acc: 0.9014 - val_loss: 0.9381 - val_acc: 0.8257\n",
      "Epoch 148/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2210 - acc: 0.9220 - val_loss: 1.0848 - val_acc: 0.8211\n",
      "Epoch 149/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2593 - acc: 0.9083 - val_loss: 1.0535 - val_acc: 0.8073\n",
      "Epoch 150/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2297 - acc: 0.9186 - val_loss: 0.9487 - val_acc: 0.8257\n",
      "Epoch 151/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2326 - acc: 0.9060 - val_loss: 1.0785 - val_acc: 0.8349\n",
      "Epoch 152/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2288 - acc: 0.9060 - val_loss: 1.0416 - val_acc: 0.8303\n",
      "Epoch 153/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2405 - acc: 0.9037 - val_loss: 1.0427 - val_acc: 0.8211\n",
      "Epoch 154/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2337 - acc: 0.9128 - val_loss: 1.0278 - val_acc: 0.8165\n",
      "Epoch 155/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2361 - acc: 0.9071 - val_loss: 0.9747 - val_acc: 0.8211\n",
      "Epoch 156/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1908 - acc: 0.9346 - val_loss: 1.0761 - val_acc: 0.8119\n",
      "Epoch 157/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2167 - acc: 0.9117 - val_loss: 0.9905 - val_acc: 0.8165\n",
      "Epoch 158/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2110 - acc: 0.9094 - val_loss: 1.0515 - val_acc: 0.8028\n",
      "Epoch 159/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2220 - acc: 0.9163 - val_loss: 1.0592 - val_acc: 0.8211\n",
      "Epoch 160/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2104 - acc: 0.9266 - val_loss: 1.0116 - val_acc: 0.8394\n",
      "Epoch 161/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2117 - acc: 0.9220 - val_loss: 1.0789 - val_acc: 0.8073\n",
      "Epoch 162/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2203 - acc: 0.9128 - val_loss: 1.0810 - val_acc: 0.8028\n",
      "Epoch 163/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1996 - acc: 0.9346 - val_loss: 1.0240 - val_acc: 0.8211\n",
      "Epoch 164/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2206 - acc: 0.9128 - val_loss: 1.0668 - val_acc: 0.8165\n",
      "Epoch 165/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1977 - acc: 0.9209 - val_loss: 0.9460 - val_acc: 0.8349\n",
      "Epoch 166/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1764 - acc: 0.9266 - val_loss: 1.0096 - val_acc: 0.8257\n",
      "Epoch 167/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2252 - acc: 0.9071 - val_loss: 1.0985 - val_acc: 0.8303\n",
      "Epoch 168/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1880 - acc: 0.9232 - val_loss: 0.9556 - val_acc: 0.8349\n",
      "Epoch 169/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2006 - acc: 0.9243 - val_loss: 0.9460 - val_acc: 0.8257\n",
      "Epoch 170/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2043 - acc: 0.9186 - val_loss: 1.0052 - val_acc: 0.8349\n",
      "Epoch 171/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1721 - acc: 0.9255 - val_loss: 1.1079 - val_acc: 0.8165\n",
      "Epoch 172/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2434 - acc: 0.9094 - val_loss: 1.0170 - val_acc: 0.8349\n",
      "Epoch 173/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2018 - acc: 0.9255 - val_loss: 1.0167 - val_acc: 0.8211\n",
      "Epoch 174/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2070 - acc: 0.9220 - val_loss: 1.0477 - val_acc: 0.8257\n",
      "Epoch 175/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2012 - acc: 0.9335 - val_loss: 1.0504 - val_acc: 0.8211\n",
      "Epoch 176/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2346 - acc: 0.9083 - val_loss: 1.0063 - val_acc: 0.8165\n",
      "Epoch 177/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1992 - acc: 0.9220 - val_loss: 1.0354 - val_acc: 0.8165\n",
      "Epoch 178/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2201 - acc: 0.9083 - val_loss: 1.1297 - val_acc: 0.8257\n",
      "Epoch 179/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2271 - acc: 0.9083 - val_loss: 1.0423 - val_acc: 0.8303\n",
      "Epoch 180/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2043 - acc: 0.9232 - val_loss: 0.9946 - val_acc: 0.8119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2004 - acc: 0.9220 - val_loss: 1.0020 - val_acc: 0.8165\n",
      "Epoch 182/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2058 - acc: 0.9186 - val_loss: 1.0539 - val_acc: 0.8165\n",
      "Epoch 183/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2074 - acc: 0.9209 - val_loss: 1.0905 - val_acc: 0.8073\n",
      "Epoch 184/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2121 - acc: 0.9174 - val_loss: 0.9860 - val_acc: 0.8349\n",
      "Epoch 185/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1913 - acc: 0.9278 - val_loss: 1.0242 - val_acc: 0.8303\n",
      "Epoch 186/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2333 - acc: 0.9128 - val_loss: 1.0828 - val_acc: 0.8211\n",
      "Epoch 187/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2024 - acc: 0.9243 - val_loss: 1.0490 - val_acc: 0.8257\n",
      "Epoch 188/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2330 - acc: 0.9025 - val_loss: 0.9582 - val_acc: 0.8211\n",
      "Epoch 189/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2055 - acc: 0.9174 - val_loss: 1.1059 - val_acc: 0.8028\n",
      "Epoch 190/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2217 - acc: 0.9232 - val_loss: 1.1843 - val_acc: 0.8073\n",
      "Epoch 191/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1974 - acc: 0.9335 - val_loss: 1.0842 - val_acc: 0.8119\n",
      "Epoch 192/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1964 - acc: 0.9186 - val_loss: 1.1144 - val_acc: 0.8119\n",
      "Epoch 193/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.1939 - acc: 0.9220 - val_loss: 1.1290 - val_acc: 0.8211\n",
      "Epoch 194/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2064 - acc: 0.9300 - val_loss: 1.1322 - val_acc: 0.8073\n",
      "Epoch 195/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2386 - acc: 0.9071 - val_loss: 1.0500 - val_acc: 0.8119\n",
      "Epoch 196/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2136 - acc: 0.9209 - val_loss: 1.0067 - val_acc: 0.8257\n",
      "Epoch 197/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2084 - acc: 0.9197 - val_loss: 1.0537 - val_acc: 0.8257\n",
      "Epoch 198/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2076 - acc: 0.9083 - val_loss: 0.9936 - val_acc: 0.8303\n",
      "Epoch 199/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2050 - acc: 0.9197 - val_loss: 1.0623 - val_acc: 0.8211\n",
      "Epoch 200/200\n",
      "872/872 [==============================] - 19s 22ms/step - loss: 0.2065 - acc: 0.9255 - val_loss: 0.9688 - val_acc: 0.8349\n"
     ]
    }
   ],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "N_BATCH = 8\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.45,\n",
    "                              patience=5,\n",
    "                              min_lr=0.001)\n",
    "history = model.fit(X_tr, y_tr,\n",
    "                    batch_size = N_BATCH,\n",
    "                    epochs = 200,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (X_te, y_te),\n",
    "                    callbacks=[reduce_lr])\n",
    "\n",
    "# save model weights and training history\n",
    "model.save_weights('models/weights.h5')\n",
    "import pickle\n",
    "with open('models/history', 'wb') as f:\n",
    "        pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the model training history\n",
    "import matplotlib.pyplot as plt\n",
    "with open(\"models/history\", \"rb\") as f:\n",
    "    hist = pickle.load(f)\n",
    "    \n",
    "plt.plot(hist[\"acc\"], label = \"train accuracy\", color = \"green\")\n",
    "plt.plot(hist[\"val_acc\"], label = \"test accuracy\", color = \"blue\")\n",
    "plt.legend()\n",
    "plt.savefig(\"docs/training_history.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"./models/vgg16pretrained.h5\")\n",
    "# def predict_and_draw(i, X, y, model, classnames, save = False):\n",
    "#     x = X[i]\n",
    "#     x = x.astype(np.uint8)\n",
    "#     plt.imshow(x)\n",
    "#     x = x/ 255.0\n",
    "#     x.shape = (1, ) + x.shape\n",
    "#     p = model.predict(x)[0,0].round(2)\n",
    "#     plt.title(\"P(edible): \" + str(p) + \" Actually edible: \" + str(y[i]))\n",
    "#     if(save):\n",
    "#         plt.savefig(\"docs/prediction_\"+str(i)+\".png\")\n",
    "#     plt.show()\n",
    "    \n",
    "# draw_sample(1, X, y, classdirs[0][1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
